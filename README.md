# magnetic_skin

Finally, the skin should be capable of dynamic measurements as well as character/gesture recognition. We demonstrate a simple task of classifying digits through the soft skin, which illustrates the ability of identifying meaningful change through temporal space. We first collect a set of digits data from the magnetometer by drawing the numbers 0 through 9. The data was collected at 50 Hz. In order to extract the signals correlated with the digit, we performed a number of preprocessing steps. For the following steps, we assumed our raw magnetometer signal to be $S^d_i$ for digit $d \in \{0,\dotsc,9\}$ and time $i \in  \{1,\dotsc,t\}$. We denoted the raw magnetometer signal without any interference as $S^b$, defined by averaging signals of resting states over a set of 5 experiments.

1) We defined a positive signal $S^d_j$ = $S^d_i$ if $\delta(S^d_i, S^b) > .2S^b$. Note that due to filtering, time $j$ was no longer consecutive after this step. 2) For each $S^d_j$, if $\delta(j, j\pm1) > 3$ time steps away, we deemed element $S^d_j$ to be noise and was removed. 3) We clustered the neighboring time data points together, where a bucket $B$ consists of a series of non-consecutive $S^d_{j:j+n}$. A bucket was determined if $\delta(j+n, j+n+1) > 7$. 4) Different digits required different amount of time to write. In order to compensate for this variable, we select a fixed time length $l$. Based on the median and $80th$ percentile time lengths for all buckets $B$, we set $l=19$, since the maximum median is 19 and maximum $80th$ percentile is 21.8, close to our median. 5) For each unique bucket $S^d_{j:j+n}$ and $l=20$, we set an anchor $a = \mathrm{midpoint}(i, i+n)$. To make a consecutive series, all time points $i$ from $a - l/2$ to $a + l/2$ were selected as the final time points, such that the final data point for digit $d$ is  $X^d = S^d_{a - l/2:a + l/2}$.

The final data $X^d$ for all $d$ digits were utilized to train, cross validate and test a classification model. Each $X^d$ was flattened into a one dimensional vector. We performed grid search over parameters ($l1$ or $l2$ penalty, $C = \log_{10} n $ with $n \in (0, \dotsc, 10)$ ) for a linear SVM, with five fold cross validation on training and testing splits and an additional five fold cross validation on training and validation split. Our final model was chosen with a squared hinge loss, $l2$ penalty, and $C=0.02636$. Our final accuracy is 92.86\% on our held-out test set. 
